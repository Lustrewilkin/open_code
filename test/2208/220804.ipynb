{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test new classfier dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch.conv import EdgeWeightNorm, GraphConv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier7(nn.Module):\n",
    "    def __init__(self, arg): \n",
    "        super(Classifier7, self).__init__()\n",
    "        self.n_classes = arg.num_labels\n",
    "        self.pip_num = 3\n",
    "\n",
    "        ## // todo: need to rectify to the dynamic or use same width type model\n",
    "        Conv = []\n",
    "        Gcn = []\n",
    "        for i in range(self.pip_num):\n",
    "            Conv.append(nn.Conv1d(128, 96, kernel_size=3, stride=1, padding=i+1, dilation=i+1))\n",
    "            Gcn.append(GraphConv(96, 54, norm='none', weight=True, bias=True))\n",
    "        self.ConvList = nn.ModuleList(Conv)\n",
    "        self.GcnList = nn.ModuleList(Gcn)\n",
    "\n",
    "\n",
    "        self.pressConv = nn.Conv1d(self.pip_num, 1, kernel_size=self.pip_num, stride=1, padding=1)\n",
    "\n",
    "        self.Jk_GIN = nn.ModuleList([\n",
    "            GraphConv(54, 34, norm='none', weight=True, bias=True), \n",
    "            GraphConv(34, 25, norm='none', weight=True, bias=True), \n",
    "            GraphConv(25, 16, norm='none', weight=True, bias=True),\n",
    "            ])\n",
    "        self.classify1 = nn.Linear(75, 120)\n",
    "        self.classify2 = nn.Linear(120, self.n_classes)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(96)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(54)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(75)\n",
    "        self.actf = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        emd_h = self.BN_embedding(graph)\n",
    "        emd_h = self.dropout(emd_h)\n",
    "        logits = self.Presentation(graph, emd_h)\n",
    "        return logits, emd_h\n",
    "\n",
    "\n",
    "    def cross_connect(self, h01, h02) -> torch.Tensor:\n",
    "        h01 = h01.permute(0, 2, 1).squeeze(0)\n",
    "        return self.batchnorm1(self.actf(h01)+h02.permute(0, 2, 1).squeeze(0))\n",
    "\n",
    "    # Brain Network embedding\n",
    "    def BN_embedding(self, graph) -> torch.Tensor:\n",
    "        # conv1D 需要变形，所以要单独写个函数\n",
    "        # 普通1D卷积, TCN 不合适\n",
    "        h0 = graph.ndata['h'].float().unsqueeze(0).permute(0, 2, 1) # shape = [1, 128, 18*n]\n",
    "        h0x = []\n",
    "        for i in range(3):\n",
    "            h0x.append(self.ConvList[i](h0))\n",
    "        \n",
    "        edeg_w = graph.edata['f'].float()\n",
    "        h2x = []\n",
    "        for i in range(3):\n",
    "            h1x = self.cross_connect(h0x[i%3], h0x[(i+1)%3])\n",
    "            temp = self.GcnList[i](graph, h1x, edge_weight=edeg_w)\n",
    "            h2x.append(self.actf(temp).unsqueeze(0)) # reback to node x emb\n",
    "\n",
    "        ac_h1 = self.pressConv(torch.cat(h2x, dim=0).permute(\n",
    "            1, 0, 2)).permute(1, 0, 2).squeeze(0)\n",
    "        ac_h1 = self.batchnorm2(ac_h1) # without dropout, it's indivual for module \n",
    "\n",
    "        return ac_h1\n",
    "\n",
    "    # presetation module\n",
    "    def Presentation(self, graph, emd_h) -> torch.Tensor:\n",
    "        h0x = [emd_h]\n",
    "        edeg_w = graph.edata['f'].float()\n",
    "        for i in range(len(self.Jk_GIN)):\n",
    "            h0x.append(self.actf(self.Jk_GIN[i](graph, h0x[i], edge_weight=edeg_w)))\n",
    "\n",
    "        with graph.local_scope():\n",
    "            ac_h = torch.cat(h0x[1:], 1)\n",
    "            # print(ac_h.shape)\n",
    "            graph.ndata['h'] = ac_h\n",
    "            # print(graph)\n",
    "            hg = dgl.readout_nodes(graph, 'h', None, op='sum', ntype=None)\n",
    "            return self.classify2(self.classify1(self.batchnorm3(hg)))\n",
    "\n",
    "    @ property\n",
    "    def num_labels(self):\n",
    "        return 5\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import surpport.Args as A\n",
    "reload(A)\n",
    "import surpport.mySQL as mySQL\n",
    "# def prepare():\n",
    "#     arg = A.Args()\n",
    "#     model = Classifier4(arg)  # 实际模型\n",
    "#     # model = Classifier6(arg)\n",
    "#     base_rcd = mySQL.gen_base_rcd(arg)\n",
    "#     recorder = {'base': base_rcd}\n",
    "#     return arg, model, recorder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = A.Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'surpport.nnstructure' from 'e:\\\\CODEBASE\\\\myDGL\\\\FirstDGL\\\\surpport\\\\nnstructure.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import surpport.nnstructure as mynn\n",
    "reload(mynn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier7(arg)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg.d_prepare()\n",
    "arg.m_info(m_name='m4', m_task='220807_test', num=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def toypy(a, b, c):\n",
    "#     print(a+b*c)\n",
    "\n",
    "# args = [1,2,3]\n",
    "# toypy(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'surpport.myfunction' from 'e:\\\\CODEBASE\\\\myDGL\\\\FirstDGL\\\\surpport\\\\myfunction.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import surpport.dataprocess as DP\n",
    "import surpport.myfunction as MF\n",
    "reload(DP)\n",
    "reload(MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=6e-5,\n",
    "                        eps=1e-8, weight_decay=0.1) \n",
    "arg, tr_dataloader, ts_dataloader = DP.dataload(arg, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, l in tr_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = g.ndata['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nd.view(g.batch_size, 18, -1)\n",
    "nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg.tr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rcd = mySQL.gen_base_rcd(arg)\n",
    "recorder = {'base': base_rcd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(arg.tar_path+'\\\\Journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 01, Iter 005,train loss = 1.7542, train acc = 0.1875\n",
      "Epoch 01, Iter 010,train loss = 1.7813, train acc = 0.1875\n",
      "Epoch 01, Iter 015,train loss = 1.6585, train acc = 0.2188\n",
      "Epoch 01, Iter 020,train loss = 1.7175, train acc = 0.1875\n",
      "Epoch 01, Iter 025,train loss = 1.5395, train acc = 0.2500\n",
      "Epoch 01, Iter 030,train loss = 1.7440, train acc = 0.1562\n",
      "Epoch 01, Iter 035,train loss = 1.7914, train acc = 0.1562\n",
      "Epoch 01, Iter 040,train loss = 1.7855, train acc = 0.0938\n",
      "Epoch 01, Iter 045,train loss = 1.6683, train acc = 0.2188\n",
      "Epoch 01, val loss = 1.6796, val acc = 0.2108\n",
      "未达到期望，未保存模型\n",
      "2\n",
      "Epoch 02, Iter 005,train loss = 1.6818, train acc = 0.1250\n",
      "Epoch 02, Iter 010,train loss = 1.7044, train acc = 0.3125\n",
      "Epoch 02, Iter 015,train loss = 1.5996, train acc = 0.1875\n",
      "Epoch 02, Iter 020,train loss = 1.7050, train acc = 0.1250\n",
      "Epoch 02, Iter 025,train loss = 1.6833, train acc = 0.3125\n",
      "Epoch 02, Iter 030,train loss = 1.6212, train acc = 0.2500\n",
      "Epoch 02, Iter 035,train loss = 1.6726, train acc = 0.1875\n",
      "Epoch 02, Iter 040,train loss = 1.6767, train acc = 0.1562\n",
      "Epoch 02, Iter 045,train loss = 1.6861, train acc = 0.1875\n",
      "Epoch 02, val loss = 1.6652, val acc = 0.1827\n",
      "未达到期望，未保存模型\n",
      "3\n",
      "Epoch 03, Iter 005,train loss = 1.7013, train acc = 0.1875\n",
      "Epoch 03, Iter 010,train loss = 1.7713, train acc = 0.1562\n",
      "Epoch 03, Iter 015,train loss = 1.7332, train acc = 0.1875\n",
      "Epoch 03, Iter 020,train loss = 1.6446, train acc = 0.1562\n",
      "Epoch 03, Iter 025,train loss = 1.6517, train acc = 0.2188\n",
      "Epoch 03, Iter 030,train loss = 1.7658, train acc = 0.0938\n",
      "Epoch 03, Iter 035,train loss = 1.7995, train acc = 0.0938\n",
      "Epoch 03, Iter 040,train loss = 1.6584, train acc = 0.2500\n",
      "Epoch 03, Iter 045,train loss = 1.7054, train acc = 0.1562\n",
      "Epoch 03, val loss = 1.6798, val acc = 0.1890\n",
      "未达到期望，未保存模型\n",
      "4\n",
      "Epoch 04, Iter 005,train loss = 1.5500, train acc = 0.2812\n",
      "Epoch 04, Iter 010,train loss = 1.6683, train acc = 0.0625\n",
      "Epoch 04, Iter 015,train loss = 1.7590, train acc = 0.1562\n",
      "Epoch 04, Iter 020,train loss = 1.6411, train acc = 0.2500\n",
      "Epoch 04, Iter 025,train loss = 1.7138, train acc = 0.1250\n",
      "Epoch 04, Iter 030,train loss = 1.7160, train acc = 0.2188\n",
      "Epoch 04, Iter 035,train loss = 1.7572, train acc = 0.1250\n",
      "Epoch 04, Iter 040,train loss = 1.6882, train acc = 0.2500\n",
      "Epoch 04, Iter 045,train loss = 1.7398, train acc = 0.2812\n",
      "Epoch 04, val loss = 1.6672, val acc = 0.2030\n",
      "未达到期望，未保存模型\n",
      "5\n",
      "Epoch 05, Iter 005,train loss = 1.6485, train acc = 0.2188\n",
      "Epoch 05, Iter 010,train loss = 1.6556, train acc = 0.2188\n",
      "Epoch 05, Iter 015,train loss = 1.7188, train acc = 0.2500\n",
      "Epoch 05, Iter 020,train loss = 1.6720, train acc = 0.1562\n",
      "Epoch 05, Iter 025,train loss = 1.7353, train acc = 0.2188\n",
      "Epoch 05, Iter 030,train loss = 1.6143, train acc = 0.2812\n",
      "Epoch 05, Iter 035,train loss = 1.7875, train acc = 0.0938\n",
      "Epoch 05, Iter 040,train loss = 1.6950, train acc = 0.1562\n",
      "Epoch 05, Iter 045,train loss = 1.6155, train acc = 0.2188\n",
      "Epoch 05, val loss = 2.2975, val acc = 0.1858\n",
      "未达到期望，未保存模型\n",
      "6\n",
      "Epoch 06, Iter 005,train loss = 1.7182, train acc = 0.1250\n",
      "Epoch 06, Iter 010,train loss = 1.7779, train acc = 0.0938\n",
      "Epoch 06, Iter 015,train loss = 1.6374, train acc = 0.1562\n",
      "Epoch 06, Iter 020,train loss = 1.5955, train acc = 0.2812\n",
      "Epoch 06, Iter 025,train loss = 1.7767, train acc = 0.1250\n",
      "Epoch 06, Iter 030,train loss = 1.7741, train acc = 0.0938\n",
      "Epoch 06, Iter 035,train loss = 1.6961, train acc = 0.2188\n",
      "Epoch 06, Iter 040,train loss = 1.6309, train acc = 0.2188\n",
      "Epoch 06, Iter 045,train loss = 1.7710, train acc = 0.1875\n",
      "Epoch 06, val loss = 1.6697, val acc = 0.2077\n",
      "未达到期望，未保存模型\n",
      "7\n",
      "Epoch 07, Iter 005,train loss = 1.7680, train acc = 0.1562\n",
      "Epoch 07, Iter 010,train loss = 1.6745, train acc = 0.1875\n",
      "Epoch 07, Iter 015,train loss = 1.6317, train acc = 0.2500\n",
      "Epoch 07, Iter 020,train loss = 1.7319, train acc = 0.0938\n",
      "Epoch 07, Iter 025,train loss = 1.6500, train acc = 0.1875\n",
      "Epoch 07, Iter 030,train loss = 1.6556, train acc = 0.2500\n",
      "Epoch 07, Iter 035,train loss = 1.6842, train acc = 0.1250\n",
      "Epoch 07, Iter 040,train loss = 1.6602, train acc = 0.1250\n",
      "Epoch 07, Iter 045,train loss = 1.6582, train acc = 0.2500\n",
      "Epoch 07, val loss = 1.6996, val acc = 0.2050\n",
      "未达到期望，未保存模型\n",
      "8\n",
      "Epoch 08, Iter 005,train loss = 1.6593, train acc = 0.1250\n",
      "Epoch 08, Iter 010,train loss = 1.7750, train acc = 0.2500\n",
      "Epoch 08, Iter 015,train loss = 1.7469, train acc = 0.2188\n",
      "Epoch 08, Iter 020,train loss = 1.6906, train acc = 0.2188\n",
      "Epoch 08, Iter 025,train loss = 1.7213, train acc = 0.1875\n",
      "Epoch 08, Iter 030,train loss = 1.7427, train acc = 0.1250\n",
      "Epoch 08, Iter 035,train loss = 1.7706, train acc = 0.1562\n",
      "Epoch 08, Iter 040,train loss = 1.6000, train acc = 0.3438\n",
      "Epoch 08, Iter 045,train loss = 1.7447, train acc = 0.1250\n",
      "Epoch 08, val loss = 1.6821, val acc = 0.1906\n",
      "未达到期望，未保存模型\n",
      "9\n",
      "Epoch 09, Iter 005,train loss = 1.7797, train acc = 0.1250\n",
      "Epoch 09, Iter 010,train loss = 1.7149, train acc = 0.2188\n",
      "Epoch 09, Iter 015,train loss = 1.7409, train acc = 0.2188\n",
      "Epoch 09, Iter 020,train loss = 1.7687, train acc = 0.1875\n",
      "Epoch 09, Iter 025,train loss = 1.7502, train acc = 0.1250\n",
      "Epoch 09, Iter 030,train loss = 1.6944, train acc = 0.1250\n",
      "Epoch 09, Iter 035,train loss = 1.6996, train acc = 0.2188\n",
      "Epoch 09, Iter 040,train loss = 1.7218, train acc = 0.1562\n",
      "Epoch 09, Iter 045,train loss = 1.5891, train acc = 0.2500\n",
      "Epoch 09, val loss = 1.6733, val acc = 0.1952\n",
      "未达到期望，未保存模型\n",
      "10\n",
      "Epoch 10, Iter 005,train loss = 1.7293, train acc = 0.1250\n",
      "Epoch 10, Iter 010,train loss = 1.7030, train acc = 0.0938\n",
      "Epoch 10, Iter 015,train loss = 1.7395, train acc = 0.1875\n",
      "Epoch 10, Iter 020,train loss = 1.6919, train acc = 0.0938\n",
      "Epoch 10, Iter 025,train loss = 1.6930, train acc = 0.1875\n",
      "Epoch 10, Iter 030,train loss = 1.7665, train acc = 0.1250\n",
      "Epoch 10, Iter 035,train loss = 1.5910, train acc = 0.1875\n",
      "Epoch 10, Iter 040,train loss = 1.7753, train acc = 0.0938\n",
      "Epoch 10, Iter 045,train loss = 1.6897, train acc = 0.2188\n",
      "Epoch 10, val loss = 1.6758, val acc = 0.1932\n",
      "未达到期望，未保存模型\n",
      "best acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# c7\n",
    "for epoch in range(1, 10+1):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_loss, tr_acc = MF.train(\n",
    "        epoch,\n",
    "        model, opt, tr_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(\n",
    "        epoch,\n",
    "        model, opt, ts_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier4(\n",
       "  (conv1): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "  (conv3): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "  (gconv11): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "  (gconv12): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "  (gconv13): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "  (pressConv): Conv1d(3, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (gconv2): GraphConv(in=54, out=25, normalization=none, activation=None)\n",
       "  (gconv3): GraphConv(in=25, out=13, normalization=none, activation=None)\n",
       "  (gconv4): GraphConv(in=25, out=11, normalization=none, activation=None)\n",
       "  (classify1): Linear(in_features=49, out_features=27, bias=True)\n",
       "  (classify2): Linear(in_features=27, out_features=5, bias=True)\n",
       "  (actf): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surpport.nnstructure import Classifier4\n",
    "model = Classifier4(arg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 01, Iter 005,train loss = 452.0110, train acc = 0.3125\n",
      "Epoch 01, Iter 010,train loss = 520.3890, train acc = 0.1875\n",
      "Epoch 01, Iter 015,train loss = 506.2921, train acc = 0.2188\n",
      "Epoch 01, Iter 020,train loss = 649.5613, train acc = 0.3438\n",
      "Epoch 01, Iter 025,train loss = 588.6839, train acc = 0.2500\n",
      "Epoch 01, Iter 030,train loss = 494.4493, train acc = 0.1250\n",
      "Epoch 01, Iter 035,train loss = 534.6677, train acc = 0.2188\n",
      "Epoch 01, Iter 040,train loss = 570.6909, train acc = 0.2188\n",
      "Epoch 01, Iter 045,train loss = 507.5078, train acc = 0.2812\n",
      "Epoch 01, val loss = 560.4825, val acc = 0.1832\n",
      "未达到期望，未保存模型\n",
      "2\n",
      "Epoch 02, Iter 005,train loss = 408.7426, train acc = 0.3125\n",
      "Epoch 02, Iter 010,train loss = 493.0602, train acc = 0.2188\n",
      "Epoch 02, Iter 015,train loss = 473.8531, train acc = 0.1562\n",
      "Epoch 02, Iter 020,train loss = 656.1123, train acc = 0.2188\n",
      "Epoch 02, Iter 025,train loss = 675.6329, train acc = 0.1875\n",
      "Epoch 02, Iter 030,train loss = 508.8904, train acc = 0.1875\n",
      "Epoch 02, Iter 035,train loss = 858.2495, train acc = 0.1250\n",
      "Epoch 02, Iter 040,train loss = 460.0514, train acc = 0.2188\n",
      "Epoch 02, Iter 045,train loss = 572.6755, train acc = 0.2500\n",
      "Epoch 02, val loss = 549.0401, val acc = 0.2082\n",
      "未达到期望，未保存模型\n",
      "3\n",
      "Epoch 03, Iter 005,train loss = 646.1323, train acc = 0.2188\n",
      "Epoch 03, Iter 010,train loss = 463.0594, train acc = 0.3125\n",
      "Epoch 03, Iter 015,train loss = 603.6310, train acc = 0.1875\n",
      "Epoch 03, Iter 020,train loss = 436.3892, train acc = 0.1875\n",
      "Epoch 03, Iter 025,train loss = 385.8084, train acc = 0.1250\n",
      "Epoch 03, Iter 030,train loss = 394.0592, train acc = 0.3438\n",
      "Epoch 03, Iter 035,train loss = 706.6705, train acc = 0.1562\n",
      "Epoch 03, Iter 040,train loss = 661.8047, train acc = 0.2188\n",
      "Epoch 03, Iter 045,train loss = 421.0680, train acc = 0.2812\n",
      "Epoch 03, val loss = 556.2416, val acc = 0.2092\n",
      "未达到期望，未保存模型\n",
      "4\n",
      "Epoch 04, Iter 005,train loss = 677.8158, train acc = 0.1250\n",
      "Epoch 04, Iter 010,train loss = 460.2855, train acc = 0.2812\n",
      "Epoch 04, Iter 015,train loss = 449.4586, train acc = 0.1875\n",
      "Epoch 04, Iter 020,train loss = 504.7333, train acc = 0.2500\n",
      "Epoch 04, Iter 025,train loss = 323.3466, train acc = 0.3125\n",
      "Epoch 04, Iter 030,train loss = 565.1760, train acc = 0.3750\n",
      "Epoch 04, Iter 035,train loss = 466.9270, train acc = 0.2500\n",
      "Epoch 04, Iter 040,train loss = 658.8109, train acc = 0.1875\n",
      "Epoch 04, Iter 045,train loss = 401.6584, train acc = 0.2812\n",
      "Epoch 04, val loss = 555.8234, val acc = 0.1958\n",
      "未达到期望，未保存模型\n",
      "5\n",
      "Epoch 05, Iter 005,train loss = 440.4050, train acc = 0.1875\n",
      "Epoch 05, Iter 010,train loss = 623.3906, train acc = 0.1875\n",
      "Epoch 05, Iter 015,train loss = 483.2830, train acc = 0.2812\n",
      "Epoch 05, Iter 020,train loss = 495.1856, train acc = 0.2188\n",
      "Epoch 05, Iter 025,train loss = 654.7458, train acc = 0.2500\n",
      "Epoch 05, Iter 030,train loss = 705.6542, train acc = 0.1562\n",
      "Epoch 05, Iter 035,train loss = 802.6976, train acc = 0.1250\n",
      "Epoch 05, Iter 040,train loss = 615.5513, train acc = 0.1875\n",
      "Epoch 05, Iter 045,train loss = 371.3376, train acc = 0.2188\n",
      "Epoch 05, val loss = 559.6621, val acc = 0.2082\n",
      "未达到期望，未保存模型\n",
      "6\n",
      "Epoch 06, Iter 005,train loss = 633.7413, train acc = 0.2188\n",
      "Epoch 06, Iter 010,train loss = 483.7342, train acc = 0.3125\n",
      "Epoch 06, Iter 015,train loss = 610.2718, train acc = 0.3750\n",
      "Epoch 06, Iter 020,train loss = 710.8669, train acc = 0.1562\n",
      "Epoch 06, Iter 025,train loss = 579.6506, train acc = 0.2188\n",
      "Epoch 06, Iter 030,train loss = 691.3783, train acc = 0.0625\n",
      "Epoch 06, Iter 035,train loss = 600.7242, train acc = 0.2188\n",
      "Epoch 06, Iter 040,train loss = 534.3715, train acc = 0.2188\n",
      "Epoch 06, Iter 045,train loss = 553.9994, train acc = 0.2500\n",
      "Epoch 06, val loss = 558.5416, val acc = 0.1968\n",
      "未达到期望，未保存模型\n",
      "7\n",
      "Epoch 07, Iter 005,train loss = 552.8902, train acc = 0.2188\n",
      "Epoch 07, Iter 010,train loss = 473.2126, train acc = 0.2188\n",
      "Epoch 07, Iter 015,train loss = 498.7539, train acc = 0.2500\n",
      "Epoch 07, Iter 020,train loss = 599.7698, train acc = 0.1250\n",
      "Epoch 07, Iter 025,train loss = 422.2808, train acc = 0.3125\n",
      "Epoch 07, Iter 030,train loss = 444.4401, train acc = 0.1875\n",
      "Epoch 07, Iter 035,train loss = 446.0168, train acc = 0.1562\n",
      "Epoch 07, Iter 040,train loss = 610.0021, train acc = 0.1562\n",
      "Epoch 07, Iter 045,train loss = 361.6398, train acc = 0.3438\n",
      "Epoch 07, val loss = 570.9035, val acc = 0.2114\n",
      "未达到期望，未保存模型\n",
      "8\n",
      "Epoch 08, Iter 005,train loss = 772.4281, train acc = 0.1875\n",
      "Epoch 08, Iter 010,train loss = 436.1153, train acc = 0.2500\n",
      "Epoch 08, Iter 015,train loss = 467.6596, train acc = 0.1562\n",
      "Epoch 08, Iter 020,train loss = 1020.0524, train acc = 0.1875\n",
      "Epoch 08, Iter 025,train loss = 552.9963, train acc = 0.1562\n",
      "Epoch 08, Iter 030,train loss = 759.2892, train acc = 0.1250\n",
      "Epoch 08, Iter 035,train loss = 621.6260, train acc = 0.1250\n",
      "Epoch 08, Iter 040,train loss = 826.5194, train acc = 0.1875\n",
      "Epoch 08, Iter 045,train loss = 642.2618, train acc = 0.1250\n",
      "Epoch 08, val loss = 547.8206, val acc = 0.2113\n",
      "未达到期望，未保存模型\n",
      "9\n",
      "Epoch 09, Iter 005,train loss = 501.9506, train acc = 0.1562\n",
      "Epoch 09, Iter 010,train loss = 720.7855, train acc = 0.2812\n",
      "Epoch 09, Iter 015,train loss = 616.5846, train acc = 0.3438\n",
      "Epoch 09, Iter 020,train loss = 511.8726, train acc = 0.1875\n",
      "Epoch 09, Iter 025,train loss = 518.1648, train acc = 0.1562\n",
      "Epoch 09, Iter 030,train loss = 626.1600, train acc = 0.2188\n",
      "Epoch 09, Iter 035,train loss = 671.5139, train acc = 0.1250\n",
      "Epoch 09, Iter 040,train loss = 515.8040, train acc = 0.1875\n",
      "Epoch 09, Iter 045,train loss = 362.5659, train acc = 0.3125\n",
      "Epoch 09, val loss = 555.8426, val acc = 0.2155\n",
      "未达到期望，未保存模型\n",
      "10\n",
      "Epoch 10, Iter 005,train loss = 425.1203, train acc = 0.1875\n",
      "Epoch 10, Iter 010,train loss = 586.5038, train acc = 0.1562\n",
      "Epoch 10, Iter 015,train loss = 542.8563, train acc = 0.3125\n",
      "Epoch 10, Iter 020,train loss = 595.9184, train acc = 0.2188\n",
      "Epoch 10, Iter 025,train loss = 623.8384, train acc = 0.2188\n",
      "Epoch 10, Iter 030,train loss = 447.6041, train acc = 0.3125\n",
      "Epoch 10, Iter 035,train loss = 603.5321, train acc = 0.2188\n",
      "Epoch 10, Iter 040,train loss = 699.3818, train acc = 0.1875\n",
      "Epoch 10, Iter 045,train loss = 614.3716, train acc = 0.1875\n",
      "Epoch 10, val loss = 566.5822, val acc = 0.1921\n",
      "未达到期望，未保存模型\n",
      "best acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10+1):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_loss, tr_acc = MF.train(\n",
    "        epoch,\n",
    "        model, opt, tr_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(\n",
    "        epoch,\n",
    "        model, opt, ts_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DLtorch-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0f4871174d17c2bcac589796388e07be3c0794fb1edf9d00f099d67ef52f7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
