{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型代码优化测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch.conv import EdgeWeightNorm, GraphConv\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import surpport.Args as A\n",
    "import surpport.mySQL as mySQL\n",
    "import surpport.dataprocess as DP\n",
    "import surpport.myfunction as MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier7(nn.Module):\n",
    "    def __init__(self, arg): \n",
    "        super(Classifier7, self).__init__()\n",
    "        self.n_classes = arg.num_labels\n",
    "        self.pip_num = 3\n",
    "        self.pt_num = 3\n",
    "\n",
    "        ## // todo: need to rectify to the dynamic or use same width type model\n",
    "        Conv = []\n",
    "        Gcn = []\n",
    "        for i in range(self.pip_num):\n",
    "            Conv.append(nn.Conv1d(128, 96, kernel_size=3, stride=1, padding=i+1, dilation=i+1))\n",
    "            Gcn.append(GraphConv(96, 54, norm='right', weight=True, bias=True))\n",
    "        self.ConvList = nn.ModuleList(Conv)\n",
    "        self.GcnList = nn.ModuleList(Gcn)\n",
    "\n",
    "\n",
    "        self.pressConv = nn.Conv1d(self.pip_num, 1, kernel_size=self.pip_num, stride=1, padding='same')\n",
    "\n",
    "        self.PR_GIN = nn.ModuleList([\n",
    "            GraphConv(54, 34, norm='right', weight=True, bias=True),  \n",
    "            GraphConv(34, 25, norm='right', weight=True, bias=True), \n",
    "            GraphConv(25, 16, norm='right', weight=True, bias=True),\n",
    "            ])\n",
    "        self.classify1 = nn.Linear(75, 120)\n",
    "        self.classify2 = nn.Linear(120, self.n_classes)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(96)\n",
    "        self.PR_BN = nn.ModuleList([nn.BatchNorm1d(54),\n",
    "            nn.BatchNorm1d(34),nn.BatchNorm1d(16),])\n",
    "        self.batchnorm3 = nn.BatchNorm1d(75)\n",
    "        self.actf = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        emd_h = self.BN_embedding(graph)\n",
    "        emd_h = self.dropout(emd_h)\n",
    "        logits = self.Presentation(graph, emd_h)\n",
    "        return logits, emd_h\n",
    "\n",
    "\n",
    "    def cross_connect(self, h01, h02) -> torch.Tensor:\n",
    "        h01 = h01.permute(0, 2, 1).squeeze(0)\n",
    "        return self.batchnorm1(self.actf(h01)+h02.permute(0, 2, 1).squeeze(0))\n",
    "\n",
    "    # Brain Network embedding\n",
    "    def BN_embedding(self, graph) -> torch.Tensor:\n",
    "        # conv1D 需要变形，所以要单独写个函数\n",
    "        # 普通1D卷积, TCN 不合适\n",
    "        h0 = graph.ndata['h'].float().unsqueeze(0).permute(0, 2, 1) # shape = [1, 128, 18*n]\n",
    "        h0x = []\n",
    "        for i in range(self.pip_num):\n",
    "            h0x.append(self.ConvList[i](h0))\n",
    "        \n",
    "        edeg_w = graph.edata['f'].float()\n",
    "        h2x = []\n",
    "        for i in range(self.pip_num):\n",
    "            h1x = self.cross_connect(h0x[i%self.pip_num], h0x[(i+1)%self.pip_num])\n",
    "            temp = self.GcnList[i](graph, h1x, edge_weight=edeg_w)\n",
    "            h2x.append(self.actf(temp).unsqueeze(0)) # reback to node x emb\n",
    "\n",
    "        ac_h1 = self.pressConv(torch.cat(h2x, dim=0).permute(\n",
    "            1, 0, 2)).permute(1, 0, 2).squeeze(0)\n",
    "        ac_h1 = self.PR_BN[0](ac_h1) # without dropout, it's indivual for module \n",
    "\n",
    "        return ac_h1\n",
    "\n",
    "    # presetation module\n",
    "    def Presentation(self, graph, emd_h) -> torch.Tensor:\n",
    "        h0x = [emd_h]\n",
    "        edeg_w = graph.edata['f'].float()\n",
    "        for i in range(len(self.PR_GIN)):\n",
    "            h0x.append(self.actf(self.PR_GIN[i](graph, h0x[i], edge_weight=edeg_w)))\n",
    "\n",
    "        with graph.local_scope():\n",
    "            ac_h = torch.cat(h0x[1:], 1)\n",
    "            # print(ac_h.shape)\n",
    "            graph.ndata['nh'] = ac_h\n",
    "            # print(graph)\n",
    "            hg = dgl.readout_nodes(graph, 'nh', None, op='sum', ntype=None)\n",
    "            return self.classify2(self.classify1(hg))\n",
    "\n",
    "    @ property\n",
    "    def num_labels(self):\n",
    "        return 5\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = A.Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'surpport.nnstructure' from 'e:\\\\CODEBASE\\\\myDGL\\\\FirstDGL\\\\surpport\\\\nnstructure.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import surpport.nnstructure as mynn\n",
    "reload(mynn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier7(arg)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg.d_prepare()\n",
    "arg.m_info(m_name='m7', m_task='220808_test', num=7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "# , lr=6e-5, eps=1e-8, weight_decay=0.1) \n",
    "arg, tr_dataloader, ts_dataloader = DP.dataload(arg, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg.tr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rcd = mySQL.gen_base_rcd(arg)\n",
    "recorder = {'base': base_rcd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(arg.tar_path+'\\\\Journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速修改时使用\n",
    "model = Classifier7(arg)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c7\n",
    "st = 30\n",
    "for epoch in range(st, st+30):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_loss, tr_acc = MF.train(\n",
    "        epoch,\n",
    "        model, opt, tr_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(\n",
    "        epoch,\n",
    "        model, opt, ts_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surpport.nnstructure import Classifier4\n",
    "model = Classifier4(arg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 10+1):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_loss, tr_acc = MF.train(\n",
    "        epoch,\n",
    "        model, opt, tr_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(\n",
    "        epoch,\n",
    "        model, opt, ts_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不变量的讨论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 1], [2, 4, 2], [3, 4, 3]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = [[1 for _ in range(3)], [2 for _ in range(3)], [3 for _ in range(3)]]\n",
    "\n",
    "for gi in g:\n",
    "    gi[1] = 4\n",
    "\n",
    "g\n",
    "## ! 我日，这个会改，那不是出大问题了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w & b research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:mb9pd4ey) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cdb1af966744afa9f402f787a753bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">daily-monkey-1</strong>: <a href=\"https://wandb.ai/lustrewilkin/my-test-project/runs/mb9pd4ey\" target=\"_blank\">https://wandb.ai/lustrewilkin/my-test-project/runs/mb9pd4ey</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220808_203457-mb9pd4ey\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:mb9pd4ey). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\CODEBASE\\myDGL\\FirstDGL\\wandb\\run-20220808_204000-1i4kvtmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lustrewilkin/my-test-project/runs/1i4kvtmu\" target=\"_blank\">hardy-armadillo-2</a></strong> to <a href=\"https://wandb.ai/lustrewilkin/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/lustrewilkin/my-test-project/runs/1i4kvtmu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1953a26cf40>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '220808'\n",
    "wandb.init(project=\"my-test-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 30,\n",
    "  \"batch_size\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"ts_acc\": val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%wandb is a cell magic, but the cell body is empty. Did you mean the line magic %wandb (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.watch(model, torch.nn.functional.cross_entropy(), log_freq=40, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DLtorch-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0f4871174d17c2bcac589796388e07be3c0794fb1edf9d00f099d67ef52f7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
