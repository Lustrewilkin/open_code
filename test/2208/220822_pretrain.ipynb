{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import surpport.mySQL as mySQL\n",
    "import surpport.myfunction as MF\n",
    "from surpport.Args import Args\n",
    "from surpport.dataprocess import dataload\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from dgl.data.utils import load_graphs\n",
    "from os.path import join\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "## v1：和 cross_Dataset 差别不大，因为需要先测试行不行，再去测试各种设计\n",
    "###    因此，保留原始训练集规模，但测试集只最后一个人，因为之前的实验已经\n",
    "###    已经证明了无法泛化，所以测试集先只保留一个人【先这么做，但实验阐述\n",
    "###    不可以这么弄】\n",
    "# todo：修改 dataset 和 opt 来完成预训练\n",
    "class PreTrain_Dataset(Dataset):\n",
    "    def __init__(self, arg) -> None:\n",
    "        super(Dataset, self).__init__()\n",
    "        self.arg = arg # type: Args\n",
    "        self.load(arg)\n",
    "    \n",
    "    def load(self, arg):\n",
    "        f = arg.select_f # type: str\n",
    "        ori = r'E:\\DATABASE\\FirstGNN\\CrossData'\n",
    "        path = join(ori, f+'_dgl_graph')\n",
    "        gdata = torch.load(path)\n",
    "        self.graphs, self.labels = gdata['graphs'], gdata['labels']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.graphs[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "def c_dataload(arg, model, opt, alpha):\n",
    "    \"\"\"cross exp dataload\n",
    "\n",
    "    Args:\n",
    "        arg (Args): Args need\n",
    "        model (nn.Moudle): ours model\n",
    "        opt (torch.opt): torch.opt\n",
    "        alpha (int): 1~10, train set contain by num of patients\n",
    "\n",
    "    Returns:\n",
    "        tuple: arg, tr_dataloader, ts_dataloader\n",
    "    \"\"\"\n",
    "    dataset = PreTrain_Dataset(arg)\n",
    "    if not arg.new_train:\n",
    "        MF.continue_tr(arg.dir, model, opt, arg)\n",
    "    else:\n",
    "        end_num = alpha * 1875 # 单人一个\n",
    "        lenth = (alpha+1) * 1875 \n",
    "        arg.tr_id = list(range(end_num))\n",
    "        arg.ts_id = list(range(end_num, lenth))\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(\n",
    "        dataset=dataset, indices=arg.tr_id)\n",
    "    test_dataset = torch.utils.data.Subset(\n",
    "        dataset=dataset, indices=arg.ts_id)\n",
    "    tr_dataloader = dataloader(\n",
    "        train_dataset, arg.batch_size, collate=MF.collate, shuffle=True)\n",
    "    ts_dataloader = dataloader(\n",
    "        test_dataset, arg.batch_size, collate=MF.collate, shuffle=True)\n",
    "    return arg, tr_dataloader, ts_dataloader\n",
    "\n",
    "def dataloader(dataset, batch_size, collate, shuffle):\n",
    "    gdataloader = GraphDataLoader(\n",
    "        dataset,\n",
    "        collate_fn=collate,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=False\n",
    "        # sampler = sampler\n",
    "    )\n",
    "    return gdataloader    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surpport.nnstructure import Classifier7\n",
    "\n",
    "def m_pre():\n",
    "    arg = Args()\n",
    "    # model = GNN.DGCN()\n",
    "    model = Classifier7(arg)\n",
    "    # model = EEGNet2()\n",
    "    model = model.cuda()\n",
    "    return arg, model\n",
    "\n",
    "def recorder_build(arg):\n",
    "    base_rcd = mySQL.gen_base_rcd(arg)\n",
    "    recorder = {'base': base_rcd}\n",
    "    return recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['kly']\n",
    "fs = [2, ]\n",
    "for f in fs:\n",
    "    arg, model = m_pre()\n",
    "    arg.d_prepare('Pre_Train', f)\n",
    "    # ! 每次运行都改\n",
    "    arg.m_info(m_name='m7', m_task='220822_pre_test', num=1)\n",
    "    base_rcd = mySQL.gen_base_rcd(arg)\n",
    "    recorder = {'base': base_rcd}\n",
    "    writer = SummaryWriter(arg.tar_path+'\\\\Journal')\n",
    "\n",
    "    # ! 根据模型修改\n",
    "    opt_arg = {'params': model.parameters(),}\n",
    "    # opt_arg = {'params': model.parameters(),'lr': 6e-5, 'eps': 1e-8, 'weight_decay': 0.1}\n",
    "    opt = torch.optim.Adam(**opt_arg)\n",
    "\n",
    "    arg, tr_dataloader, ts_dataloader = c_dataload(arg, model, opt, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 41\n",
    "step = 40\n",
    "arg.display_freq = 50\n",
    "for epoch in range(st, step+st):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_args = [epoch, model, opt, tr_dataloader, arg, writer]\n",
    "    tr_loss, tr_acc = MF.train(*tr_args)\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    tr_args[3] = ts_dataloader\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(*tr_args)\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91401404"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta = np.mean(tr_acc, axis=0)\n",
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存模型，best_acc = 0.9140\n"
     ]
    }
   ],
   "source": [
    "MF.save_best(ta, model, arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surpport.nnstructure import Classifier7\n",
    "from surpport.dataprocess import dataload\n",
    "\n",
    "def m_pre():\n",
    "    arg = Args()\n",
    "    # model = GNN.DGCN()\n",
    "    model = Classifier7(arg)\n",
    "    # model = EEGNet2()\n",
    "    model = model.cuda()\n",
    "    return arg, model\n",
    "\n",
    "def recorder_build(arg):\n",
    "    base_rcd = mySQL.gen_base_rcd(arg)\n",
    "    recorder = {'base': base_rcd}\n",
    "    return recorder\n",
    "\n",
    "names = ['kly']\n",
    "fs = [2, ]\n",
    "for f in fs:\n",
    "    arg, model = m_pre()\n",
    "    arg.d_prepare('yc', f)\n",
    "    # ! 每次运行都改\n",
    "    arg.m_info(m_name='m7', m_task='220822_pre_test', num=4)\n",
    "    base_rcd = mySQL.gen_base_rcd(arg)\n",
    "    recorder = {'base': base_rcd}\n",
    "    writer = SummaryWriter(arg.tar_path+'\\\\Journal')\n",
    "    opt = None\n",
    "    # ! 根据模型修改\n",
    "    arg, tr_dataloader, ts_dataloader = dataload(arg, model, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数冻结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Classifier7(\n",
       "  (ConvList): ModuleList(\n",
       "    (0): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (2): Conv1d(128, 96, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "  )\n",
       "  (GcnList): ModuleList(\n",
       "    (0): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "    (1): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "    (2): GraphConv(in=96, out=54, normalization=none, activation=None)\n",
       "  )\n",
       "  (pressConv): Conv1d(3, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (Jk_GIN): ModuleList(\n",
       "    (0): GraphConv(in=54, out=34, normalization=none, activation=None)\n",
       "    (1): GraphConv(in=34, out=25, normalization=none, activation=None)\n",
       "    (2): GraphConv(in=25, out=16, normalization=none, activation=None)\n",
       "  )\n",
       "  (classify1): Linear(in_features=75, out_features=120, bias=True)\n",
       "  (classify2): Linear(in_features=120, out_features=5, bias=True)\n",
       "  (batchnorm1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (actf): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'classify1' in 'classify1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jk_GIN.0.weight\n",
      "Jk_GIN.0.bias\n",
      "Jk_GIN.1.weight\n",
      "Jk_GIN.1.bias\n",
      "Jk_GIN.2.weight\n",
      "Jk_GIN.2.bias\n",
      "classify1.weight\n",
      "classify1.bias\n",
      "classify2.weight\n",
      "classify2.bias\n"
     ]
    }
   ],
   "source": [
    "fronze = ['classify1', 'Jk_GIN',\n",
    "'classify2']\n",
    "for k, v in model.named_parameters():\n",
    "    flag = False\n",
    "    for condi in fronze:\n",
    "        if condi in k:\n",
    "            flag = True\n",
    "            print(k)\n",
    "            break\n",
    "    v.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jk_GIN.0.weight\n",
      "Jk_GIN.0.bias\n",
      "Jk_GIN.1.weight\n",
      "Jk_GIN.1.bias\n",
      "Jk_GIN.2.weight\n",
      "Jk_GIN.2.bias\n",
      "classify1.weight\n",
      "classify1.bias\n",
      "classify2.weight\n",
      "classify2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_arg = {'params': filter(lambda p: p.requires_grad, model.parameters()),}\n",
    "# opt_arg = {'params': model.parameters(),'lr': 6e-5, 'eps': 1e-8, 'weight_decay': 0.1}\n",
    "opt = torch.optim.Adam(**opt_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(r'E:\\DATABASE\\FirstGNN\\220822_pre_test\\Pre_Train\\m7_1\\bmodel.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "# opt.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预训练开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 81\n",
    "step = 40\n",
    "arg.display_freq = 5\n",
    "for epoch in range(st, step+st):\n",
    "    print(epoch)\n",
    "    recorder[str(epoch)+'-th'] = dict()\n",
    "    rd = recorder[str(epoch)+'-th']\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    # 前两个是list\n",
    "    tr_args = [epoch, model, opt, tr_dataloader, arg, writer]\n",
    "    tr_loss, tr_acc = MF.train(*tr_args)\n",
    "    mySQL.rcd_log(tr_loss, tr_acc, writer, rd, epoch, 'train')\n",
    "\n",
    "    tr_args[3] = ts_dataloader\n",
    "    el_loss, el_acc, logits, labels = MF.evaluate(*tr_args)\n",
    "\n",
    "    mySQL.rcd_log(el_loss, el_acc, writer, rd, epoch, 'test')\n",
    "    mySQL.rcd_result(logits, labels, rd)\n",
    "\n",
    "    val_acc = np.mean(el_acc, axis=0)\n",
    "    MF.save_best(val_acc, model, arg)\n",
    "\n",
    "    mySQL.save_final(epoch, model, val_acc, arg, opt)\n",
    "\n",
    "mySQL.save_recorder(recorder, arg, 'flow')\n",
    "print('best acc: %.4f' % (arg.best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DLtorch-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0f4871174d17c2bcac589796388e07be3c0794fb1edf9d00f099d67ef52f7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
