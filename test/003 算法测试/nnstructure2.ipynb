{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from FirstDGL.surrport.dataprocess import dataloader, Arg, my_dataset\n",
    "# import myfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结构\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, arg):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.in_dim = arg.input_ft\n",
    "        self.hidden_dim1 = arg.hidden_dim_1\n",
    "        self.n_classes = arg.num_labels\n",
    "\n",
    "        self.conv1 = nn.Conv1d(12, 1, 3, 1, padding=2)\n",
    "        self.gconv1 = GraphConv(self.in_dim, self.hidden_dim1,\n",
    "                                norm='none', weight=True, bias=True)\n",
    "        self.classify1 = nn.Linear(self.hidden_dim1, self.n_classes)\n",
    "        self.actf = nn.Tanh()\n",
    "\n",
    "    def forward(self, graph):\n",
    "        h0 = self.conv1(graph.ndata['h'].float())\n",
    "        h1 = self.gconv1(graph, h0  # graph.ndata['h'].float()\n",
    "                         , edge_weight=graph.edata['f'].float())\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h1\n",
    "            return self.classify1(hg)  \n",
    "    \n",
    "    @property         \n",
    "    def num_labels(self):\n",
    "        return 5\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = dp.Arg()\n",
    "model = Classifier(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "arg = dp.Arg()\n",
    "batch_size = arg.batch_size\n",
    "device = torch.device('cuda:0')\n",
    "model = Classifier(arg)\n",
    "model = model.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), weight_decay=0.3)\n",
    "\n",
    "dataset = my_dataset(raw_dir=arg.raw_data_dir, save_dir=arg.save_data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size])\n",
    "\n",
    "tr_dataloader = dataloader(train_dataset, arg.batch_size, collate=MF.collate)\n",
    "ts_dataloader = dataloader(test_dataset, arg.batch_size, collate=MF.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, arg.epoch_num+1):\n",
    "    # 由于图经过拼合，所以需要多一个dataloader的过程\n",
    "    loss_list, acc_list = MF.train(\n",
    "        epoch,\n",
    "        model, opt, tr_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = MF.evaluate(\n",
    "        epoch,\n",
    "        model, opt, ts_dataloader,\n",
    "        arg,\n",
    "        writer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7370]],\n",
       "\n",
       "         [[ 1.4117]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4138]],\n",
       "\n",
       "         [[-0.6331]]],\n",
       "\n",
       "\n",
       "        [[[-0.6768]],\n",
       "\n",
       "         [[-0.7786]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "bn = nn.BatchNorm2d(num_features=3, affine=False, track_running_stats=False)\n",
    "x = torch.rand(3,2,1,1)*10000\n",
    "o_bn = bn(x)   # 官方代码\n",
    "o_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5407,  1.1947],\n",
       "         [-0.5370,  0.6121],\n",
       "         [-1.0116,  0.8733]]),\n",
       " tensor([[ 0.3044,  1.0644],\n",
       "         [-0.9479,  0.3874],\n",
       "         [-1.4994,  0.6910]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Norm2D(x):\n",
    "    y = (x-torch.mean(x))/torch.sqrt(torch.var(x)+1e-5)\n",
    "    return y\n",
    "x = torch.randn(3,2)\n",
    "y = Norm2D(x)\n",
    "x,y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DLtorch-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "e0f4871174d17c2bcac589796388e07be3c0794fb1edf9d00f099d67ef52f7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
